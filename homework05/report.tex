%%
%% This is file `sample-acmtog.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,journal,bibtex,acmtog')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmtog.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmtog]{acmart}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{XXXXXXX.XXXXXXX}

%%
%% These commands are for a JOURNAL article.
\acmJournal{TOG}
% \acmVolume{37}
% \acmNumber{4}
\acmArticle{1}
\acmMonth{10}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%% \acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Homework 5 Report}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Kai Hogan}
% \authornote{Both authors contributed equally to this research.}
\email{khogan@uoregon.edu}



%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Hogan}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
This report compares the performance of the SPMV COO algorithm using MPI communication using different configurations of compute nodes, MPI tasks per node, and CPU's per task.
\end{abstract}


%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010169.10010170</concept_id>
       <concept_desc>Computing methodologies~Parallel algorithms</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010169.10010170.10010171</concept_id>
       <concept_desc>Computing methodologies~Shared memory algorithms</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809</concept_id>
       <concept_desc>Theory of computation~Design and analysis of algorithms</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Parallel algorithms}
\ccsdesc[300]{Computing methodologies~Shared memory algorithms}
\ccsdesc[300]{Theory of computation~Design and analysis of algorithms}
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
% \keywords{Keywords}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Findings}
\subsection{Communication Times}

\subsubsection{Vector Broadcasting}
Configurations 1 and 4 were the least efficient at broadcasting the vector to all processes, taking approximately 0.001 seconds each. The remaining three configurations performed about 10 percent faster, completing the operation in roughly 0.0009 seconds. Configuration 5 achieved the fastest vector broadcasting time at 0.000803 seconds. The relatively small variation across configurations suggests that broadcasting a single vector is not a significant bottleneck.

\subsubsection{Vector Broadcasting}
All configurations performed similarly for the matrix scatter operation, with times ranging between 0.015 and 0.030 seconds. Configuration 5 achieved the fastest time at 0.017 seconds, while Configuration 4 was slightly slower at 0.030 seconds. Despite the range appearing modest, Configuration 5's scatter time was around 40 percent faster than Configuration 4's, indicating that having fewer MPI ranks (4 vs 8) reduces the overhead of distributing the sparse matrix data across processes.

\subsubsection{Result Vector Reduction}
The result vector reduction showed the most dramatic variation in performance across configurations. Configurations 2 and 3 took approximately 0.014-0.018 seconds, while Configurations 1 and 4 were faster at just under 0.009 seconds. Configuration 5 was by far the most efficient, completing the reduction in only 0.000742 seconds, more than 10× faster than Configurations 2 and 3. This pattern clearly demonstrates that reduction time scales with the number of MPI ranks: fewer ranks mean less communication overhead during the collective reduction operation, making it a critical factor in multi-node performance.


\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{communication_times.png}
    \caption{Communication Times}
    \label{fig:placeholder}
    \Description{Graph 1}
\end{figure}

\subsection{SpMV Computation Times}
The first three configurations all exhibited similar SpMV COO performance, taking slightly under 0.3 seconds each: Configuration 1 completed in 0.225 seconds, Configuration 2 in 0.258 seconds, and Configuration 3 in 0.291 seconds. Configurations 4 and 5 were significantly more performant, taking 0.080 and 0.041 seconds respectively. Configuration 5's superior SpMV performance is attributable to its higher core count at 112 total cores; it had 3.5× more computational resources than the 32-core configurations. Since the SpMV COO code was parallelized using OpenMP, Configuration 5 could fully exploit this parallelism by assigning more threads to each MPI task.
The most striking finding is that Configuration 4 was approximately 3.6× faster than Configuration 3 despite both having identical core counts (32 cores). This substantial performance discrepancy stems from Configuration 4 utilizing a single node while Configuration 3 distributed work across four separate nodes. When all processes share the same memory system on a single node, they benefit from better cache coherency and lower memory access latency. 

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{computation_times.png}
    \caption{SPMV and Lock initialization times}
    \label{fig:placeholder}
    \Description{Graph 2}
\end{figure}

\subsection{Total Execution Time}
Configurations 1 through 3 demonstrated nearly identical overall performance despite their different node configurations. Configuration 1 took 0.261 seconds to complete the entire operation, Configuration 2 was slightly slower at 0.298 seconds, and Configuration 3 was the slowest at 0.336 seconds. Configurations 4 and 5 significantly outperformed the first three: Configuration 4 completed in 0.119 seconds, while Configuration 5 was nearly twice as fast at 0.061 seconds. This progression reveals that simply adding more nodes without adjusting the MPI-to-OpenMP balance provides no performance benefit and can actually degrade performance due to increased communication overhead.
SpMV COO was clearly the dominant bottleneck, consuming between 68 percent and 87 percent of total execution time across all configurations. Matrix scattering emerged as a secondary bottleneck, accounting for 9 percent to 29 percent of the total runtime. The fact that Configurations 4 and 5 dramatically reduced the SpMV computation time while maintaining relatively stable communication times explains their superior overall performance—they addressed the primary bottleneck through better parallelization strategy.

\subsection{Key Conclusions}
1. Configuration 5 was the fastest by a significant margin, nearly twice as fast as the second-best configuration. While its computational advantage (112 vs 32 cores) played a major role, its performance gains also stemmed from an optimal balance: fewer MPI ranks minimized communication overhead while maximizing OpenMP threads per rank fully exploited shared-memory parallelism.

2. Scaling nodes without scaling CPUs per task led to declines in performance. Configurations 1 through 3 progressively slowed down as more nodes were added while keeping CPUs per task constant at 1-4. This counterintuitive result reveals that the algorithm's communication overhead and inter-node synchronization costs outweigh any potential benefits from distributing work across more nodes. For this particular COO SpMV implementation, shared-memory parallelism (OpenMP) is far more effective than distributed-memory parallelism (MPI).

3. Result vector reduction time more than doubled from 1 to 4 nodes (0.009s → 0.018s), clearly showing that communication costs grow significantly with more MPI ranks. However, since result reduction represented only 1-6 percent of total execution time, this slowdown had an insignificant impact on overall performance.


\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{total_time.png}
    \caption{Total Times}
    \label{fig:placeholder}
    \Description{Graph 3}
\end{figure}


%%
%% If your work has an appendix, this is the place to put it.
% \appendix

% \section{Research Methods}

% \subsection{Part One}

% Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi
% malesuada, quam in pulvinar varius, metus nunc fermentum urna, id
% sollicitudin purus odio sit amet enim. Aliquam ullamcorper eu ipsum
% vel mollis. Curabitur quis dictum nisl. Phasellus vel semper risus, et
% lacinia dolor. Integer ultricies commodo sem nec semper.

% \subsection{Part Two}

% Etiam commodo feugiat nisl pulvinar pellentesque. Etiam auctor sodales
% ligula, non varius nibh pulvinar semper. Suspendisse nec lectus non
% ipsum convallis congue hendrerit vitae sapien. Donec at laoreet
% eros. Vivamus non purus placerat, scelerisque diam eu, cursus
% ante. Etiam aliquam tortor auctor efficitur mattis.

% \section{Online Resources}

% Nam id fermentum dui. Suspendisse sagittis tortor a nulla mollis, in
% pulvinar ex pretium. Sed interdum orci quis metus euismod, et sagittis
% enim maximus. Vestibulum gravida massa ut felis suscipit
% congue. Quisque mattis elit a risus ultrices commodo venenatis eget
% dui. Etiam sagittis eleifend elementum.

% Nam interdum magna at lectus dignissim, ac dignissim lorem
% rhoncus. Maecenas eu arcu ac neque placerat aliquam. Nunc pulvinar
% massa et mattis lacinia.

\end{document}
\endinput
%%
%% End of file `sample-acmtog.tex'.